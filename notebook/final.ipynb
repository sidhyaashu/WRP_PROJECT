{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAdvanced NLP Approach for Automated Knowledge Gap Detection in Student Responses\\n-------------------------------------------------------------------------------\\nThis script demonstrates:\\n    - Advanced data pre-processing (tokenization, stopword removal, normalization, lemmatization)\\n    - Semantic similarity analysis using Sentence-BERT\\n    - Knowledge gap detection by comparing key concepts\\n    - Detailed feedback generation for open-ended responses\\n    - Visualization of similarity scores and missing concepts\\n\\nRequirements:\\n    - Python 3.x\\n    - spaCy (and the English model: en_core_web_sm)\\n    - nltk\\n    - sentence-transformers\\n    - scikit-learn\\n    - numpy\\n    - matplotlib\\n    - seaborn\\n\\nTo install required packages, you can run:\\n    pip install spacy nltk sentence-transformers scikit-learn numpy matplotlib seaborn\\n    python -m spacy download en_core_web_sm\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Advanced NLP Approach for Automated Knowledge Gap Detection in Student Responses\n",
    "-------------------------------------------------------------------------------\n",
    "This script demonstrates:\n",
    "    - Advanced data pre-processing (tokenization, stopword removal, normalization, lemmatization)\n",
    "    - Semantic similarity analysis using Sentence-BERT\n",
    "    - Knowledge gap detection by comparing key concepts\n",
    "    - Detailed feedback generation for open-ended responses\n",
    "    - Visualization of similarity scores and missing concepts\n",
    "\n",
    "Requirements:\n",
    "    - Python 3.x\n",
    "    - spaCy (and the English model: en_core_web_sm)\n",
    "    - nltk\n",
    "    - sentence-transformers\n",
    "    - scikit-learn\n",
    "    - numpy\n",
    "    - matplotlib\n",
    "    - seaborn\n",
    "\n",
    "To install required packages, you can run:\n",
    "    pip install spacy nltk sentence-transformers scikit-learn numpy matplotlib seaborn\n",
    "    python -m spacy download en_core_web_sm\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download nltk data (if not already downloaded)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab') # Add this line to download punkt_tab\n",
    "STOPWORDS = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Explain the process of photosynthesis.\",\n",
    "    \"Describe the significance of the water cycle in Earth's ecosystem.\",\n",
    "    \"Discuss the impact of the Industrial Revolution on modern society.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_answers = [\n",
    "    \"Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods from carbon dioxide and water. It involves the chlorophyll in leaves and generates oxygen as a byproduct.\",\n",
    "    \"The water cycle is crucial as it distributes fresh water across the globe, supporting life. It involves processes like evaporation, condensation, precipitation, and infiltration, maintaining ecological balance.\",\n",
    "    \"The Industrial Revolution marked a major turning point in history; it led to advancements in technology, manufacturing, and transportation, significantly influencing modern society's economic and social structures.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_responses = [\n",
    "    \"Plants use sunlight to make food from carbon dioxide and water, releasing oxygen.\",\n",
    "    \"Water evaporates, forms clouds, and comes back as rain, which is important for life.\",\n",
    "    \"The Industrial Revolution changed how things were made and had effects on today.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess text by lowercasing, removing non-alphabetic characters, \n",
    "    stopwords, and performing lemmatization.\n",
    "    \"\"\"\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in STOPWORDS]\n",
    "    # Return cleaned text\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_responses = [preprocess_text(resp) for resp in student_responses]\n",
    "preprocessed_references = [preprocess_text(ans) for ans in reference_answers]\n",
    "preprocessed_questions = [preprocess_text(q) for q in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Similarity Analysis\n",
    "# Encode responses and reference answers\n",
    "response_embeddings = sbert_model.encode(preprocessed_responses)\n",
    "reference_embeddings = sbert_model.encode(preprocessed_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity scores\n",
    "similarity_scores = []\n",
    "for resp_emb, ref_emb in zip(response_embeddings, reference_embeddings):\n",
    "    sim_score = util.cos_sim(resp_emb, ref_emb).item()\n",
    "    similarity_scores.append(sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display similarity scores\n",
    "print(\"\\nSemantic Similarity Scores:\")\n",
    "for idx, score in enumerate(similarity_scores):\n",
    "    print(f\"Response {idx+1} Similarity: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Gap Detection\n",
    "# --------------------------\n",
    "def extract_key_concepts(text):\n",
    "    \"\"\"\n",
    "    Extract key concepts (nouns and noun phrases) from the text.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    concepts = set()\n",
    "    for chunk in doc.noun_chunks:\n",
    "        concepts.add(chunk.lemma_.lower())\n",
    "    for token in doc:\n",
    "        if token.pos_ in ['NOUN', 'PROPN']:\n",
    "            concepts.add(token.lemma_.lower())\n",
    "    return concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify missing concepts in student responses\n",
    "def identify_missing_concepts(response_text, reference_text):\n",
    "    response_concepts = extract_key_concepts(response_text)\n",
    "    reference_concepts = extract_key_concepts(reference_text)\n",
    "    missing_concepts = reference_concepts - response_concepts\n",
    "    return missing_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Feedback Generation\n",
    "# --------------------------\n",
    "def generate_feedback(response_idx, threshold=0.75):\n",
    "    \"\"\"\n",
    "    Generate detailed feedback for a student's response.\n",
    "    \"\"\"\n",
    "    sim_score = similarity_scores[response_idx]\n",
    "    student_text = student_responses[response_idx]\n",
    "    reference_text = reference_answers[response_idx]\n",
    "    \n",
    "    feedback = f\"Your Response:\\n{student_text}\\n\"\n",
    "    feedback += f\"\\nSimilarity Score: {sim_score:.4f}\\n\"\n",
    "    if sim_score >= threshold:\n",
    "        feedback += \"Great work! Your response covers the key concepts.\\n\"\n",
    "    else:\n",
    "        missing_concepts = identify_missing_concepts(preprocessed_responses[response_idx], preprocessed_references[response_idx])\n",
    "        if missing_concepts:\n",
    "            feedback += \"Your response is missing the following key concepts:\\n\"\n",
    "            feedback += \", \".join(missing_concepts) + \"\\n\"\n",
    "        else:\n",
    "            feedback += \"Your response could be elaborated further to include more details.\\n\"\n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feedback for each student response\n",
    "print(\"\\nDetailed Feedback:\")\n",
    "for idx in range(len(student_responses)):\n",
    "    print(f\"\\nFeedback for Response {idx+1}:\\n{generate_feedback(idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Similarity Scores and Missing Concepts\n",
    "# --------------------------\n",
    "def plot_similarity_scores(similarity_scores):\n",
    "    \"\"\"\n",
    "    Plot similarity scores for student responses.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x=[f'Response {i+1}' for i in range(len(similarity_scores))],\n",
    "                y=similarity_scores, palette='viridis')\n",
    "    plt.axhline(y=0.75, color='red', linestyle='--')\n",
    "    plt.xlabel('Student Responses')\n",
    "    plt.ylabel('Similarity Score')\n",
    "    plt.title('Semantic Similarity Scores of Student Responses')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "plot_similarity_scores(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Missing Concepts\n",
    "def visualize_missing_concepts(response_idx):\n",
    "    \"\"\"\n",
    "    Create a word cloud of missing concepts for a student's response.\n",
    "    \"\"\"\n",
    "    from wordcloud import WordCloud\n",
    "    missing_concepts = identify_missing_concepts(preprocessed_responses[response_idx], preprocessed_references[response_idx])\n",
    "    if missing_concepts:\n",
    "        text = \" \".join(missing_concepts)\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Missing Concepts in Response {response_idx+1}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing concepts for each response\n",
    "for idx in range(len(student_responses)):\n",
    "    visualize_missing_concepts(idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
