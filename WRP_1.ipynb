{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPmv3PX81ChNvuo6ss6m2rs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidhyaashu/WRP_PROJECT/blob/sidhya/WRP_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "0V0yIFI3_MNi",
        "outputId": "74a547d1-1b21-42a9-8287-98a8a10d6638"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-2-c9c94db4ae29>, line 171)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-c9c94db4ae29>\"\u001b[0;36m, line \u001b[0;32m171\u001b[0m\n\u001b[0;31m    ::contentReference[oaicite:0]{index=0}\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "Advanced NLP Approach for Automated Knowledge Gap Detection in Student Responses\n",
        "-------------------------------------------------------------------------------\n",
        "This script demonstrates:\n",
        "    - Data pre-processing (tokenization, stopword removal, normalization)\n",
        "    - Semantic similarity analysis using T5 transformer model\n",
        "    - Dynamic topic modeling using BERTopic\n",
        "    - Real-time feedback generation\n",
        "    - Comprehensive evaluation metrics\n",
        "\n",
        "Requirements:\n",
        "    - Python 3.x\n",
        "    - transformers\n",
        "    - torch\n",
        "    - nltk\n",
        "    - bertopic\n",
        "    - scikit-learn\n",
        "    - numpy\n",
        "\n",
        "To install required packages, you can run:\n",
        "    pip install transformers torch nltk bertopic scikit-learn numpy\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from bertopic import BERTopic\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Download nltk stopwords (if not already downloaded)\n",
        "nltk.download('stopwords')\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Load T5 Model and Tokenizer\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "\n",
        "# --------------------------\n",
        "# Data Collection (Sample Data)\n",
        "# --------------------------\n",
        "# Example student responses and a reference answer\n",
        "student_responses = [\n",
        "    \"The process of photosynthesis converts light energy into chemical energy.\",\n",
        "    \"Photosynthesis is the method by which plants use sunlight to create food, but they need water too.\",\n",
        "    \"Plants perform a process to turn sunlight into energy, though the details are not clear.\",\n",
        "    \"Plants do something with light energy to make food.\"\n",
        "]\n",
        "\n",
        "reference_answer = \"Photosynthesis is the process by which green plants convert light energy into chemical energy by synthesizing sugars from carbon dioxide and water.\"\n",
        "\n",
        "# --------------------------\n",
        "# Pre-Processing Function\n",
        "# --------------------------\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess text by lowercasing, removing non-alphabetic characters, and stopwords.\n",
        "    \"\"\"\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    # Remove non-alphabetic characters\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    # Tokenize and remove stopwords\n",
        "    tokens = [word for word in text.split() if word not in STOPWORDS]\n",
        "    # Return cleaned text\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Preprocess all responses\n",
        "preprocessed_responses = [preprocess_text(resp) for resp in student_responses]\n",
        "preprocessed_reference = preprocess_text(reference_answer)\n",
        "\n",
        "# --------------------------\n",
        "# Semantic Similarity Analysis Function\n",
        "# --------------------------\n",
        "def compute_similarity(student_text, reference_text):\n",
        "    \"\"\"\n",
        "    Compute semantic similarity between student text and reference text using T5 model.\n",
        "    \"\"\"\n",
        "    input_text = f\"stsb sentence1: {student_text} sentence2: {reference_text}\"\n",
        "    inputs = t5_tokenizer.encode(input_text, return_tensors='pt')\n",
        "    outputs = t5_model.generate(inputs, max_length=5)\n",
        "    similarity_score = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return float(similarity_score)\n",
        "\n",
        "# Compute similarity scores for each student response\n",
        "print(\"\\nSemantic Similarity Scores:\")\n",
        "for idx, response in enumerate(preprocessed_responses):\n",
        "    sim_score = compute_similarity(response, preprocessed_reference)\n",
        "    print(f\"Response {idx+1} Similarity: {sim_score:.4f}\")\n",
        "\n",
        "# --------------------------\n",
        "# Dynamic Topic Modeling with BERTopic\n",
        "# --------------------------\n",
        "def perform_topic_modeling(texts):\n",
        "    \"\"\"\n",
        "    Perform dynamic topic modeling using BERTopic on the provided texts.\n",
        "    \"\"\"\n",
        "    # Initialize BERTopic model\n",
        "    topic_model = BERTopic()\n",
        "    # Fit the model on the texts\n",
        "    topics, _ = topic_model.fit_transform(texts)\n",
        "    return topic_model, topics\n",
        "\n",
        "# Combine student responses and reference answer for topic modeling analysis\n",
        "all_texts = preprocessed_responses + [preprocessed_reference]\n",
        "topic_model, topics = perform_topic_modeling(all_texts)\n",
        "\n",
        "print(\"\\nIdentified Topics:\")\n",
        "for topic in set(topics):\n",
        "    print(f\"Topic {topic}: {topic_model.get_topic(topic)}\")\n",
        "\n",
        "# --------------------------\n",
        "# Real-Time Feedback Generation\n",
        "# --------------------------\n",
        "def generate_feedback(student_text, reference_text, threshold=0.8):\n",
        "    \"\"\"\n",
        "    Generate feedback based on semantic similarity and identified topics.\n",
        "    \"\"\"\n",
        "    sim_score = compute_similarity(student_text, reference_text)\n",
        "    if sim_score >= threshold:\n",
        "        feedback = \"Good job! Your response aligns well with the reference answer.\"\n",
        "    else:\n",
        "        feedback = \"Your response is missing some key concepts. Consider reviewing the following topics: \"\n",
        "        # Identify missing topics\n",
        "        student_topics = perform_topic_modeling([student_text])[1]\n",
        "        reference_topics = perform_topic_modeling([reference_text])[1]\n",
        "        missing_topics = set(reference_topics) - set(student_topics)\n",
        "        for topic in missing_topics:\n",
        "            feedback += f\"\\n- {topic_model.get_topic(topic)}\"\n",
        "    return feedback\n",
        "\n",
        "# Generate feedback for each student response\n",
        "print(\"\\nFeedback for Student Responses:\")\n",
        "for idx, response in enumerate(preprocessed_responses):\n",
        "    feedback = generate_feedback(response, preprocessed_reference)\n",
        "    print(f\"\\nResponse {idx+1} Feedback:\\n{feedback}\")\n",
        "\n",
        "# --------------------------\n",
        "# Evaluation Metrics\n",
        "# --------------------------\n",
        "# For demonstration purposes, assume binary classification: 1 for correct, 0 for incorrect\n",
        "# In practice, these labels should come from a labeled dataset\n",
        "true_labels = [1, 1, 0, 0]  # Ground truth labels\n",
        "predicted_labels = [1 if compute_similarity(resp, preprocessed_reference) >= 0.8 else 0 for resp in preprocessed_responses]\n",
        "\n",
        "precision = precision_score(true_labels, predicted_labels)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1-Score:  {f1:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# --------------------------\n",
        "# Main Pipeline Execution\n",
        "# --------------------------\n",
        "def main():\n",
        "    print(\"\\n--- Running Full Pipeline ---\\n\")\n",
        "\n",
        "    # 1. Pre-process Responses\n",
        "    print(\"Preprocessing student responses...\")\n",
        "    processed_responses = [preprocess_text]\n",
        "::contentReference[oaicite:0]{index=0}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NfPAJ3tg_OsX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}